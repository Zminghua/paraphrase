###########################################################################
#    > File Name: run.conf
#    > Author: zhangminghua
#    > Mail: zhangmh1993@163.com
#    > Created Time: 2016.8.30 10:21:06
###########################################################################


path=/home/work/zmh/nlp/paraphrase
python=${path}/python/bin/python
corpus=${path}/data/weibo.post
config=${path}/run.yaml
log=${path}/log


############################ 9个处理模块的控制开关
run_uniq=0
run_preprocess=0
run_seg=0
run_key_word=0
run_pair_sim=0
run_split_para=0
run_parser=0
run_simple_filter=0
run_context_extract=0


############################ 第一阶段 : 预料去重
input_0=${corpus}
output_0=${corpus}.uniq
output_sort=${corpus}.sort


############################ 第一阶段 : 预料预处理
input_1=${output_0}
output_1=${output_0}.preprocess


############################ 第一阶段 : ansj分词
input_2=${output_1}
output_2=${output_1}.seg


############################ 第一阶段 : 计算关键词
input_3=${output_2}
output_3=${output_2}.key
stopword=${path}/lib/stop


############################ 第一阶段 : 分桶,计算句对相似性
input_4=${output_3}
output_4=${output_3}.sim
ltp_model=${path}/lib/ltp_data/


############################ 第一阶段 : 平行句对筛选与分离
input_5=${output_4}
output_source_5=${output_4}.en
output_target_5=${output_4}.fr
source_lib=${path}/lib/source.lib
target_lib=${path}/lib/target.lib


############################ 第二阶段 : StanfordParser抽取短语对
input_source_6=${output_source_5}
input_target_6=${output_target_5}
output_6=${path}/data/phrase.table
is_full_parser=1


############################ 第二阶段 : 简单规则过滤
input_7=${output_6}
output_pivot=${output_6}.pivot
output_7=${output_6}.simple
lm_model=${path}/lib/lm.fr-en.arpa.en
wordnet=${path}/lib/wordNet
is_phrase_pivot=0


############################ 第三阶段 : 分布相似度过滤
input_8=${output_7}
output_8=${output_7}.context
context=${path}/data/context
para_lib=${path}/lib/para.lib


